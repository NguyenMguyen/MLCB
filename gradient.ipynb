{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between two methods should be small: 2.189822947941729e-08\n",
      "Difference between two methods should be small: 4.271689035066838e-09\n"
     ]
    }
   ],
   "source": [
    "def check_grad(fn, gr, X):\n",
    "    # convert X to an 1d array, 1 for loop needed\n",
    "    X_flat = X.reshape(-1)\n",
    "    shape_X = X.shape                 # original shape of X\n",
    "    num_grad = np.zeros_like(X)      # numerical grad, shape = shape of X\n",
    "    grad_flat = np.zeros_like(X_flat)  # 1d version of grad\n",
    "    eps = 1e-6                        # a small number, 1e-10 -> 1e-6 is usually good\n",
    "    numElems = X_flat.shape[0]        # number of elements in X\n",
    "\n",
    "    # calculate numerical gradient\n",
    "    for i in range(numElems):         # iterate over all elements in X\n",
    "        Xp_flat = X_flat.copy()\n",
    "        Xn_flat = X_flat.copy()\n",
    "        Xp_flat[i] += eps\n",
    "        Xn_flat[i] -= eps\n",
    "        Xp = Xp_flat.reshape(shape_X)\n",
    "        Xn = Xn_flat.reshape(shape_X)\n",
    "        grad_flat[i] = (fn(Xp) - fn(Xn))/(2*eps)\n",
    "\n",
    "    num_grad = grad_flat.reshape(shape_X)\n",
    "\n",
    "    diff = np.linalg.norm(num_grad - gr(X))\n",
    "    print('Difference between two methods should be small:', diff)\n",
    "\n",
    "\n",
    "# ==== check if grad(trace(A*X)) == A^T ====\n",
    "m, n = 10, 20\n",
    "A = np.random.rand(m, n)\n",
    "X = np.random.rand(n, m)\n",
    "\n",
    "\n",
    "def fn1(X):\n",
    "    return np.trace(A.dot(X))\n",
    "\n",
    "\n",
    "def gr1(X):\n",
    "    return A.T\n",
    "\n",
    "\n",
    "check_grad(fn1, gr1, X)\n",
    "\n",
    "# ==== check if grad(x^T*A*X) == (A + A^T)*x ====\n",
    "A = np.random.rand(m, m)\n",
    "x = np.random.rand(m, 1)\n",
    "\n",
    "\n",
    "def fn2(x):\n",
    "    return x.T.dot(A).dot(x)\n",
    "\n",
    "\n",
    "def gr2(x):\n",
    "    return (A + A.T).dot(x)\n",
    "\n",
    "\n",
    "check_grad(fn2, gr2, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31671a60cee805c34c73116577b485118ff3a75c458d3004d49632c19702ac60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
